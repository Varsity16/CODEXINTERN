import pandas as pd
from sklearn.preprocessing import LabelEncoder
from sklearn.naive_bayes import CategoricalNB
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
# Sample dataset
data = {
'GPA': ['High', 'Low', 'Medium', 'High', 'Low', 'Medium', 'High'],
'Internships': ['Yes', 'No', 'Yes', 'No', 'No', 'No', 'Yes'],
'Projects': ['Good', 'Poor', 'Good', 'Average', 'Poor', 'Average', 'Good'],
'Communication': ['Good', 'Poor', 'Average', 'Good', 'Poor', 'Average', 'Good'],
'JobOffer': ['Yes', 'No', 'Yes', 'Yes', 'No', 'No', 'Yes']
}
df = pd.DataFrame(data)
# Encode categorical features
le = LabelEncoder()
for col in df.columns:
    df[col] = le.fit_transform(df[col])
# Features and target
X = df.drop('JobOffer', axis=1)
y = df['JobOffer']
# Split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)
# Naive Bayes for categorical data
model = CategoricalNB()
model.fit(X_train, y_train)
# Predict
y_pred = model.predict(X_test)
# Accuracy
print("Accuracy:", accuracy_score(y_test, y_pred))
# Predict for new student
# GPA=High, Internship=Yes, Project=Good, Communication=Good
sample = pd.DataFrame([[2, 1, 1, 1]]) # You must encode the same way
prediction = model.predict(sample)
print("Job Offer Prediction (0=No, 1=Yes):", prediction[0])
